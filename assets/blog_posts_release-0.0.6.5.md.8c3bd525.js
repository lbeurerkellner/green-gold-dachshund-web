import{_ as n,o as t,c as o,Q as e,k as a,a as s}from"./chunks/framework.c2adf1ba.js";const _=JSON.parse('{"title":"LMQL becomes simpler and adds llama.cpp","description":"","frontmatter":{"date":"2023-07-13T00:00:00.000Z","title":"LMQL becomes simpler and adds llama.cpp"},"headers":[],"relativePath":"blog/posts/release-0.0.6.5.md","filePath":"blog/posts/release-0.0.6.5.md"}'),l={name:"blog/posts/release-0.0.6.5.md"},p=e(`<h1 id="lmql-becomes-simpler-and-adds-llama-cpp" tabindex="-1">LMQL becomes simpler and adds llama.cpp <a class="header-anchor" href="#lmql-becomes-simpler-and-adds-llama-cpp" aria-label="Permalink to &quot;LMQL becomes simpler and adds llama.cpp&quot;">​</a></h1><p><span class="date">July 13, 2023</span></p><p>Today we are releasing LMQL 0.0.6.5. This update contains a major simplification of the LMQL syntax, moving it much closer to standard Python. It also includes a <code>llama.cpp</code> based inference backend, several bug fixes and other minor improvements.</p><p>You can try the latest version of LMQL in your browser at <a href="https://lmql.ai/playground" target="_blank" rel="noreferrer">lmql.ai/playground</a> or install it via <code>pip install lmql</code>.</p><h2 id="one-line-is-all-it-takes" tabindex="-1">One Line Is All It Takes <a class="header-anchor" href="#one-line-is-all-it-takes" aria-label="Permalink to &quot;One Line Is All It Takes&quot;">​</a></h2><p>Most notably, 0.0.6.5 comes with several simplifications of the core syntax of LMQL. Of course, all changes are backwards compatible, so you can continue to use your existing query code and move to the new version without any changes.</p><p>With this, we aim to minimize syntactic overhead, employing sensible defaults to enable more concise programs like the following:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="hljs"><code><span class="line"><span class="hljs-string">&quot;One line is all it takes <span class="hljs-placeholder">[CONTINUATION]</span>&quot;</span>
</span></code></pre></div>`,8),i=a("div",{class:"language-promptdown vp-adaptive-theme"},[a("button",{title:"Copy Code",class:"copy"}),a("span",{class:"lang"},"promptdown"),a("pre",{"pd-text":`One line is all it takes [CONTINUATION|Fallin' in love with me.]
`,animate:"true",__animate:"true","animate-speed":"50",class:"promptdown promptdown-compiled",style:{opacity:"1"}},[a("p",{"pd-shadow-id":"1",text:"O","pd-insertion-point":"true"},[s("One line is all it takes "),a("span",{"pd-shadow-id":"3","pd-instant":"false",text:"",class:"promptdown-var color-pink"},[a("span",{"pd-shadow-id":"4",text:"C",class:"promptdown-var-name"},"CONTINUATION"),s("Fallin' in love with me.")]),s(`
`)])])],-1),r=e(`<p><strong>Sensible Defaults</strong> This is possible because LMQL now automatically assumes <code>argmax</code> and <code>openai/text-davinci-003</code> as (configurable) default model. If you prefer to use a different model or custom decoder settings, you can still specify them explicitly, e.g. in the <code>@lmql.query</code> decorator function as demonstrated later in this post.</p><p>Without any additional configuration, the simple query code above translates to a full LMQL program like this:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="hljs"><code><span class="line"><span class="hljs-keyword">argmax</span> <span class="hljs-string">&quot;One line is all it takes <span class="hljs-placeholder">[CONTINUATION]</span>&quot;</span> <span class="hljs-keyword">from</span> <span class="hljs-string">&quot;openai/text-davinci-003&quot;</span>
</span></code></pre></div><br><h3 id="inline-constraints" tabindex="-1">Inline Constraints <a class="header-anchor" href="#inline-constraints" aria-label="Permalink to &quot;Inline Constraints&quot;">​</a></h3><p>LMQL now allows you to specify several inline <code>where</code> constraints. This enables constraints that refer to local program variables, which means constraints can now be dependent on previous model outputs.</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="hljs"><code><span class="line"><span class="hljs-string">&quot;A list of awesome Dua Lipa songs:\\n&quot;</span>
songs = []

<span class="hljs-string">&quot;- New Rules\\n&quot;</span>
<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>):
    <span class="hljs-string">&quot;-<span class="hljs-placeholder">[SONG]</span>\\n&quot;</span> <span class="hljs-keyword">where</span> STOPS_BEFORE(SONG, <span class="hljs-string">&quot;\\n&quot;</span>)
    songs.append(SONG)

<span class="hljs-string">&quot;Out of these, my favorite is<span class="hljs-placeholder">[FAVORITE]</span>&quot;</span> <span class="hljs-keyword">where</span> FAVORITE <span class="hljs-keyword">in</span> songs
</span></code></pre></div>`,7),c=a("div",{class:"language-promptdown vp-adaptive-theme"},[a("button",{title:"Copy Code",class:"copy"}),a("span",{class:"lang"},"promptdown"),a("pre",{"pd-text":`A list of awesome Dua Lipa songs:⏎
- New Rules
- [SONG|Don't Start Now]
- [SONG|IDGAF]
- [SONG|Be the One]
- [SONG|Blow Your Mind (Mwah)]
Out of these, my favorite is [FAVORITE|Don't Start Now]
`,animate:"true",__animate:"true","animate-speed":"50",class:"promptdown promptdown-compiled",style:{opacity:"1"}},[a("p",{"pd-shadow-id":"10",text:"A","pd-insertion-point":"true"},[s(`A list of awesome Dua Lipa songs:⏎
- New Rules
- `),a("span",{"pd-shadow-id":"12","pd-instant":"false",text:"",class:"promptdown-var color-pink"},[a("span",{"pd-shadow-id":"13",text:"S",class:"promptdown-var-name"},"SONG"),s("Don't Start Now")]),s(`
- `),a("span",{"pd-shadow-id":"18","pd-instant":"false",text:"",class:"promptdown-var color-pink"},[a("span",{"pd-shadow-id":"19",text:"S",class:"promptdown-var-name"},"SONG"),s("IDGAF")]),s(`
- `),a("span",{"pd-shadow-id":"24","pd-instant":"false",text:"",class:"promptdown-var color-pink"},[a("span",{"pd-shadow-id":"25",text:"S",class:"promptdown-var-name"},"SONG"),s("Be the One")]),s(`
- `),a("span",{"pd-shadow-id":"30","pd-instant":"false",text:"",class:"promptdown-var color-pink"},[a("span",{"pd-shadow-id":"31",text:"S",class:"promptdown-var-name"},"SONG"),s("Blow Your Mind (Mwah)")]),s(`
Out of these, my favorite is `),a("span",{"pd-shadow-id":"36","pd-instant":"false",text:"",class:"promptdown-var color-ochre"},[a("span",{"pd-shadow-id":"37",text:"F",class:"promptdown-var-name"},"FAVORITE"),s("Don't Start Now")]),s(`
`)])])],-1),d=e(`<p>Note also how in this example LMQL code now reads much more like standard Python code, without any additional level of indentation.</p><br><h3 id="lmql-query-functions" tabindex="-1"><code>@lmql.query</code> functions <a class="header-anchor" href="#lmql-query-functions" aria-label="Permalink to &quot;\`@lmql.query\` functions&quot;">​</a></h3><p>The overhauled syntax also makes LMQL much easier on the eyes when used with the <code>@lmql.query</code> <a href="/docs/lib/python.html">function decorator in Python</a>:</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="hljs"><code><span class="line"><span class="hljs-keyword">import</span> lmql
<span class="hljs-keyword">import</span> json

<span class="hljs-meta">@lmql.query(<span class="hljs-params">model=<span class="hljs-string">&quot;openai/text-curie-001&quot;</span>, temperature=<span class="hljs-number">0.9</span></span>)</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">summarize</span>(): 
    <span class="hljs-inline-lmql"><span style="opacity:0.4;">&#39;&#39;&#39;lmql</span>
    <span class="hljs-string">&quot;&quot;&quot;
    Provide a summary of Dua Lipa, the pop icon:
    <span>{{</span>
      &quot;name&quot;: &quot;<span class="hljs-placeholder">[STRING_VALUE]</span>&quot;,
      &quot;chart_position&quot;: <span class="hljs-placeholder">[INT_VALUE]</span>,
      &quot;top_songs&quot;: <span class="hljs-placeholder">[[
         <span class="hljs-string">&quot;[STRING_VALUE]&quot;</span>,
         <span class="hljs-string">&quot;[STRING_VALUE]&quot;</span>
      ]</span>]
    }}
    &quot;&quot;&quot;</span> <span class="hljs-keyword">where</span> STOPS_BEFORE(STRING_VALUE, <span class="hljs-string">&#39;&quot;&#39;</span>) <span class="hljs-keyword">and</span> INT(INT_VALUE) <span class="hljs-keyword">and</span> <span class="hljs-built_in">len</span>(TOKENS(INT_VALUE)) &lt; 3
    
    <span class="hljs-keyword">return</span> json.loads(context.prompt.split(<span class="hljs-string">&quot;pop icon:&quot;</span>,1)[1])
    &#39;&#39;&#39;</span>

<span class="hljs-built_in">print</span>(summarize()) <span class="hljs-comment"># {&#39;name&#39;: &#39;Dua Lipa&#39;, &#39;chart_position&#39;: 3415, &#39;top_songs&#39;: [&#39;New Rules&#39;, &#39;Havana&#39;]}</span>

</span></code></pre></div><br><h3 id="lmql-f-lambda-functions" tabindex="-1"><code>lmql.F</code> Lambda Functions <a class="header-anchor" href="#lmql-f-lambda-functions" aria-label="Permalink to &quot;\`lmql.F\` Lambda Functions&quot;">​</a></h3><p>Based on LMQL&#39;s new minimal syntax, we introduce a novel and concise way to write LLM-based lambda functions. This offers a lightweight entryway to get started with integrated small LLM-based utilities in your code, without having to write a full LMQL program.</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="hljs"><code><span class="line"><span class="hljs-keyword">import</span> lmql

summarize = lmql.F(<span class="hljs-string">&quot;Summarize the following in a few words: <span class="hljs-subst">{data}</span>: <span class="hljs-placeholder">[SUMMARY]</span>&quot;</span>)
main_subject = lmql.F(<span class="hljs-string">&quot;What is the main subject (noun) of the following text? <span class="hljs-subst">{data}</span>: <span class="hljs-placeholder">[SUBJECT]</span>&quot;</span>, 
                      <span class="hljs-string">&quot;len(TOKENS(SUBJECT)) &lt; 20&quot;</span>)

text = <span class="hljs-string">&quot;In LMQL, users can specify high-level, logical constraints ...&quot;</span>

summarize(data=text) <span class="hljs-comment"># LMQL enables high-level constraints to be enforced during text </span>
                     <span class="hljs-comment"># generation, simplifying multi-part prompting and integration.</span>
main_subject(data=text) <span class="hljs-comment"># Language Model Query Language (LMQL)</span>

</span></code></pre></div><br><br><h2 id="llama-cpp-inference-backend" tabindex="-1"><code>llama.cpp</code> Inference Backend <a class="header-anchor" href="#llama-cpp-inference-backend" aria-label="Permalink to &quot;\`llama.cpp\` Inference Backend&quot;">​</a></h2><p>LMQL now also fully integrates with the excellent <a href="https://github.com/ggerganov/llama.cpp" target="_blank" rel="noreferrer">llama.cpp</a> C++ implementation of a number of Transformer-based language models.</p><p>Using <code>llama.cpp</code> from LMQL is as simple as specifying it in the <code>from</code> clause of a query:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="hljs"><code><span class="line"><span class="hljs-keyword">argmax</span> <span class="hljs-string">&quot;Say &#39;this is a test&#39;:<span class="hljs-placeholder">[RESPONSE]</span>&quot;</span> <span class="hljs-keyword">from</span> <span class="hljs-string">&quot;llama.cpp:&lt;PATH TO WEIGHTS&gt;.bin&quot;</span>
</span></code></pre></div><p>We support, both, in-process loading of <code>llama.cpp</code>, as well as remote inference via <code>lmql serve-model</code>. To learn more about <code>llama.cpp</code> and how to use it with LMQL, check out the corresponding chapter in the LMQL <a href="/docs/models/llama.cpp.html">documentation</a>.</p><br><h2 id="other-changes" tabindex="-1">Other Changes <a class="header-anchor" href="#other-changes" aria-label="Permalink to &quot;Other Changes&quot;">​</a></h2><ul><li><p>LMQL now includes a <code>random</code> model backend, which randomly samples tokens from the GPT-2 vocabulary. This is useful for debugging and testing purposes and can be used for data generation in the context of highly constrained query programs.</p></li><li><p>Two caching issues have been fixed, avoiding cache collisions which could lead to repeated model outputs.</p></li><li><p>More robust query string parsing, allowing for <a href="/docs/language/scripted-prompting.html#escaping">robust escaping</a> of special characters <code>[</code>, <code>]</code>, <code>{</code> and <code>}</code>.</p></li><li><p>Added support for <code>transformers</code> based Llama models and the associated (fast) implementation of HF tokenizers.</p></li><li><p>Simplified Azure OpenAI support, see the relevant chapter in the <a href="/docs/models/azure.html">documentation</a>.</p></li></ul><p>We thank community members <a href="https://github.com/minosvasilias" target="_blank" rel="noreferrer">@minosvasilias</a> and <a href="https://github.com/CircArgs" target="_blank" rel="noreferrer">@CircArgs</a> for their contribution to this release.</p>`,20),h=[p,i,r,c,d];function m(u,g,f,w,b,y){return t(),o("div",null,h)}const v=n(l,[["render",m]]);export{_ as __pageData,v as default};
