import{_ as e,o as s,c as a,Q as n}from"./chunks/framework.980cae92.js";const m=JSON.parse('{"title":"LMQL Release v0.0.6.3","description":"","frontmatter":{"date":"2023-05-11T00:00:00.000Z","title":"LMQL Release v0.0.6.3"},"headers":[],"relativePath":"blog/posts/release-0.0.6.3.md","filePath":"blog/posts/release-0.0.6.3.md"}'),o={name:"blog/posts/release-0.0.6.3.md"},t=n(`<h1 id="lmql-v0-0-6-3" tabindex="-1">LMQL v0.0.6.3 <a class="header-anchor" href="#lmql-v0-0-6-3" aria-label="Permalink to &quot;LMQL v0.0.6.3&quot;">â€‹</a></h1><p><span class="date">May 11, 2023</span></p><p>Today, we are releasing LMQL v0.0.6.3. This update contains several bug fixes and improvements. The most notable changes are:</p><ul><li><p><strong>Lighter Runtime</strong> As part of our continued efforts, we made LMQL much lighter (no more mandatory <code>transformers</code> dependency). By default LMQL now no longer requires <code>transformers</code> or PyTorch. If you rely on local models, just install LMQL via <code>pip install lmql[hf]</code> to get full Transformers integration.</p></li><li><p><strong>Token Constraints</strong> A new function <code>TOKENS(...)</code> was added to the LMQL constraint language, allowing you to specify lower and upper bounds or the exact number of tokens to generate for a given variable.</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="hljs"><code><span class="line"><span class="hljs-keyword">argmax</span> 
    <span class="hljs-string">&quot;A 10 token response<span class="hljs-placeholder">[WHO]</span>&quot;</span> 
<span class="hljs-keyword">from</span> 
    <span class="hljs-string">&quot;openai/text-ada-001&quot;</span> 
<span class="hljs-keyword">where</span> 
    <span class="hljs-built_in">len</span>(TOKENS(WHO)) == <span class="hljs-number">10</span>
</span></code></pre></div></li><li><p><strong>Conditional Stopping</strong> <code>STOPS_AT</code> can now be combined with additional side conditions. This allows you to specify stopping phrases that are only enforced, once other conditions are met.</p><p>For example, below, we stop when the generated text hits a newline character, but only if the overall variable output is already at least 10 tokens long.</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="hljs"><code><span class="line"><span class="hljs-keyword">argmax</span> 
    <span class="hljs-string">&quot;Hello<span class="hljs-placeholder">[WHO]</span>&quot;</span> 
<span class="hljs-keyword">from</span> 
    <span class="hljs-string">&quot;openai/text-ada-001&quot;</span> 
<span class="hljs-keyword">where</span> 
    <span class="hljs-built_in">len</span>(TOKENS(WHO)) &gt; <span class="hljs-number">10</span> <span class="hljs-keyword">and</span> STOPS_AT(WHO, <span class="hljs-string">&quot;\\n&quot;</span>)
</span></code></pre></div></li><li><p><strong>lmql.run</strong>: Improved input validation for <code>lmql.run</code> as contributed by <a href="https://twitter.com/lfegray" target="_blank">@lfegray</a>. More specifically, <code>lmql.run</code> wil now provide more helpful error messages when client logic does not specify input values for all required query parameters.</p></li><li><p><strong>Automatic Cache Invalidation</strong>: LMQL&#39;s tokenizer cache at <code>~/.cache/lmql</code> is now invalidated automatically when upgrading to a new version. This should prevent issues with outdated cache files.</p></li></ul><blockquote><p>Note: Version 0.0.6.2 was skipped and yanked from pypi.org, as an invalid release was pushed accidentally.</p></blockquote>`,5),l=[t];function r(p,i,c,d,h,u){return s(),a("div",null,l)}const f=e(o,[["render",r]]);export{m as __pageData,f as default};
